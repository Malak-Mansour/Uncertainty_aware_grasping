{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, open3d as o3d\n",
    "def visualize_sample(strawberry_model_pcd, observation_pcd, Gt):\n",
    "    filtered_points = np.array(observation_pcd)\n",
    "    ones = np.ones((filtered_points.shape[0], 1))\n",
    "    filtered_points_h = np.hstack((filtered_points, ones))\n",
    "    strawberry_points_transformed = (Gt @ filtered_points_h.T).T[:, :3]\n",
    "\n",
    "    # Create point clouds from the data\n",
    "    pcd_strawberry = o3d.geometry.PointCloud()\n",
    "    pcd_strawberry.points = o3d.utility.Vector3dVector(strawberry_model_pcd)\n",
    "\n",
    "    pcd_loaded = o3d.geometry.PointCloud()\n",
    "    pcd_loaded.points = o3d.utility.Vector3dVector(observation_pcd)\n",
    "\n",
    "    pcd_modified = o3d.geometry.PointCloud()\n",
    "    pcd_modified.points = o3d.utility.Vector3dVector(strawberry_points_transformed)\n",
    "\n",
    "    # Create visualizer and add point clouds\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "\n",
    "    \n",
    "\n",
    "    # Add point clouds with different colors\n",
    "    pcd_strawberry.paint_uniform_color([1, 0, 0])  # Red for strawberry points\n",
    "    pcd_loaded.paint_uniform_color([0, 0, 1])      # Blue for loaded points\n",
    "    pcd_modified.paint_uniform_color([0, 1, 0])    # Green for modified points\n",
    "\n",
    "    vis.add_geometry(pcd_strawberry)\n",
    "    #vis.add_geometry(pcd_loaded)\n",
    "    vis.add_geometry(pcd_modified)\n",
    "\n",
    "    # Run visualization\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "def cal_normal(pcd, radius=0.03, max_nn=30):\n",
    "    _pcd = o3d.geometry.PointCloud()\n",
    "    _pcd.points = o3d.utility.Vector3dVector(pcd)\n",
    "    \n",
    "    _pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=max_nn))\n",
    "    # o3d.geometry.estimate_normals(_pcd, o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=max_nn))\n",
    "    normals = np.asarray(_pcd.normals)\n",
    "    return normals\n",
    "\n",
    "def regularize_pcd(pcd, n_points, is_test):\n",
    "    assert is_test is not None\n",
    "    if is_test:\n",
    "        np.random.seed(1)\n",
    "    idxs = np.random.randint(low=0, high=pcd.shape[0], size=n_points, dtype=np.int64)\n",
    "    new_pcd = pcd[idxs, :].astype(np.float32)\n",
    "    return new_pcd\n",
    "# original loss\n",
    "\n",
    "orig_strawberry_points = []\n",
    "\n",
    "strawberry_model_pcd = 'strawberry_fruit_sampled_no_leave.xyz'\n",
    "# strawberry_model_pcd = 'strawberry_y_positive.xyz'\n",
    "# gun_model_pcd ='gun.xyz'\n",
    "with open(strawberry_model_pcd, 'r') as file:\n",
    "    for line in file:\n",
    "        x_str, y_str, z_str = line.strip().split()\n",
    "        orig_strawberry_points.append((float(x_str), float(y_str), float(z_str)))\n",
    "\n",
    "# Convert to numpy array for processing\n",
    "orig_strawberry_points = np.array(orig_strawberry_points)\n",
    "print(\"orig_strawberry_points\", orig_strawberry_points.shape)\n",
    "# Convert to Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(orig_strawberry_points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Create visualizer\n",
    "# vis = o3d.visualization.Visualizer()\n",
    "# vis.create_window()\n",
    "\n",
    "# # Add geometry and run\n",
    "# vis.add_geometry(pcd)\n",
    "# vis.run()\n",
    "# vis.destroy_window()\n",
    "\n",
    "# Get all npz files in the directory\n",
    "data_dir = '/home/ali/Documents/robotic_picker/data_test/'\n",
    "dataset_files = glob.glob(os.path.join(data_dir, 'dataset*.npz'))\n",
    "print(f'Found {len(dataset_files)} dataset files')\n",
    "                \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Get all npz files in the directory\n",
    "# data_dir = '/home/ali/Documents/robotic_picker/data_test/'\n",
    "# dataset_files = glob.glob(os.path.join(data_dir, 'dataset*.npz'))\n",
    "# print(f'Found {len(dataset_files)} dataset files')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "point_counts = {}\n",
    "count = 0\n",
    "# Sort dataset files based on their numeric order\n",
    "dataset_files = sorted(dataset_files, key=lambda x: int(os.path.basename(x).replace('dataset', '').replace('.npz', '')))\n",
    "\n",
    "# Load each file and count points\n",
    "\n",
    "idx = 0\n",
    "for i in range(len(dataset_files)):\n",
    "    file_path = dataset_files[i]\n",
    "    data = np.load(file_path)\n",
    "    \n",
    "    Gt = data['y']\n",
    "    observation_points = data['X']\n",
    "    if observation_points.shape[0] > 1500:\n",
    "        print(\"shape of observation_points\", observation_points.shape, \" file path \", file_path)\n",
    "        continue\n",
    " \n",
    "    \n",
    "    print(file_path, observation_points.shape)\n",
    "\n",
    "    model_points = np.array(orig_strawberry_points)\n",
    "    ones = np.ones((model_points.shape[0], 1))\n",
    "    filtered_points_h = np.hstack((model_points, ones))\n",
    "    model_transformed = (Gt @ filtered_points_h.T).T[:, :3]\n",
    "    \n",
    "    Gt = np.linalg.inv(Gt)\n",
    "    Gt = Gt[:3]    \n",
    "    Y_transformed = model_transformed\n",
    "    Y = model_points\n",
    "    Y_normal = cal_normal(Y)\n",
    "\n",
    "    # Process original points\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(observation_points)\n",
    "\n",
    "    # Get 512 points for original data\n",
    "    if len(pcd.points) >= 512:\n",
    "        downsampled_pcd = pcd.farthest_point_down_sample(512)\n",
    "        X = np.asarray(downsampled_pcd.points)\n",
    "    else:\n",
    "        original_points = np.asarray(pcd.points)\n",
    "        repeats_needed = int(np.ceil(512 / len(original_points)))\n",
    "        X = np.tile(original_points, (repeats_needed, 1))[:512]\n",
    "\n",
    "    # Save original sample\n",
    "    X_normal = cal_normal(X)\n",
    "    sample_id = os.path.basename(file_path).replace('dataset', '').replace('.npz', '')\n",
    "    \n",
    "    # Save original data\n",
    "    input_data = {\n",
    "        \"src_pcd\": X,\n",
    "        \"src_pcd_normal\": X_normal,\n",
    "        \"model_pcd\": Y,\n",
    "        \"model_pcd_normal\": Y_normal,\n",
    "        \"model_pcd_transformed\": Y_transformed,\n",
    "        'transform_gt': Gt,\n",
    "    }\n",
    "    output_path = os.path.join(data_dir, f'processed_dataset_{idx}.npz')\n",
    "    idx += 1\n",
    "    print(f'Saving original data to {output_path}, {X.shape}')\n",
    "    np.savez(output_path, **input_data)\n",
    "    \n",
    "    # Create and save augmented versions\n",
    "    num_augmentations = 1\n",
    "    for aug_idx in range(num_augmentations):\n",
    "        # Random translation (±1 in any direction)\n",
    "        translation = np.random.uniform(-1, 1, 3)\n",
    "        \n",
    "        # Apply translation only\n",
    "        X_aug = X + translation\n",
    "        Y_transformed_aug = Y_transformed + translation\n",
    "        \n",
    "        # Calculate normals for augmented point cloud\n",
    "        X_aug_normal = cal_normal(X_aug)\n",
    "        \n",
    "        # Save augmented version\n",
    "        aug_input_data = {\n",
    "            \"src_pcd\": X_aug,\n",
    "            \"src_pcd_normal\": X_aug_normal,\n",
    "            \"model_pcd\": Y,\n",
    "            \"model_pcd_normal\": Y_normal,\n",
    "            \"model_pcd_transformed\": Y_transformed_aug,\n",
    "            'transform_gt': Gt,\n",
    "        }\n",
    "        aug_output_path = os.path.join(data_dir, f'processed_dataset_{idx}.npz')\n",
    "        idx += 1\n",
    "        print(f'Saving augmented data to {aug_output_path}, {X_aug.shape}')\n",
    "        np.savez(aug_output_path, **aug_input_data)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "\n",
    "\n",
    "data_dir = '/home/ali/Documents/robotic_picker/data_test/'\n",
    "\n",
    "file_path = os.path.join(data_dir, f'processed_dataset_{50}.npz')\n",
    "\n",
    "    # Load the data\n",
    "input_data = np.load(file_path)\n",
    "# Transform the model points using Gt\n",
    "model_points = orig_strawberry_points.copy()\n",
    "ones = np.ones((model_points.shape[0], 1))\n",
    "model_points_h = np.hstack((model_points, ones))\n",
    "Gt = input_data['transform_gt']\n",
    "Gt = np.vstack([Gt, np.array([0, 0, 0, 1])])\n",
    "model_transformed = (np.linalg.inv(Gt) @ model_points_h.T).T[:, :3]\n",
    "# Calculate and print the centroid of src_pcd\n",
    "src_pcd_centroid = np.mean(input_data['src_pcd'], axis=0)\n",
    "print(\"Source point cloud centroid:\", src_pcd_centroid)\n",
    "\n",
    "visualize_sample(input_data\n",
    "                 ['src_pcd'], input_data\n",
    "                 ['model_pcd_transformed'], np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 6, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 1, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 23, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 17, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 17, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 15, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 6, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 12, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 21, sample 1\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 18, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 20, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 9, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 5, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 8, sample 1\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 2, sample 1\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 6, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 8, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 0, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 16, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 12, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 8, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 9, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 18, sample 1\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 11, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 25, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 16, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 7, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 10, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 20, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 12, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 5, sample 1\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 3, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 10, sample 1\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 12, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 14, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 15, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 1, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 6, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 0, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 25, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 17, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 5, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 6, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 14, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 24, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 18, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 22, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 4, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 7, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 20, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 25, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 19, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 5, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 12, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 23, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 22, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 23, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 19, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 16, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 24, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 21, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 7, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 13, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 0, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 0, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 16, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 10, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 9, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 0, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 21, sample 5\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 10, sample 2\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 11, sample 1\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 2, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 21, sample 6\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 21, sample 0\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 18, sample 7\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 5, sample 3\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 1, sample 4\n",
      "Number of unique points: 16384, Total points: 16384\n",
      "Visualizing batch 24, sample 6\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Paths\n",
    "base_path = \"log/PointAttN_cd_debug_pcn/all\"\n",
    "import glob, os\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "def cal_normal(pcd, radius=0.03, max_nn=30):\n",
    "    _pcd = o3d.geometry.PointCloud()\n",
    "    _pcd.points = o3d.utility.Vector3dVector(pcd)\n",
    "    \n",
    "    _pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=max_nn))\n",
    "    # o3d.geometry.estimate_normals(_pcd, o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=max_nn))\n",
    "    normals = np.asarray(_pcd.normals)\n",
    "    return normals\n",
    "\n",
    "\n",
    "def visualize_comparison(src_pcd, src_pcd_inter, batch_idx, sample_idx):\n",
    "    # Create visualizer\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(window_name=f\"Batch {batch_idx} Sample {sample_idx}\")\n",
    "    \n",
    "    # Add source point cloud (red)\n",
    "    pcd_src = o3d.geometry.PointCloud()\n",
    "    pcd_src.points = o3d.utility.Vector3dVector(src_pcd)\n",
    "    pcd_src.paint_uniform_color([1, 0, 0])  # Red\n",
    "    vis.add_geometry(pcd_src)\n",
    "    \n",
    "    # Add interpolated point cloud (blue)\n",
    "    pcd_inter = o3d.geometry.PointCloud()\n",
    "    pcd_inter.points = o3d.utility.Vector3dVector(src_pcd_inter)\n",
    "    pcd_inter.paint_uniform_color([0, 0, 1])  # Blue\n",
    "    vis.add_geometry(pcd_inter)\n",
    "    \n",
    "    # Run visualization\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "\n",
    "\n",
    "# Process each file in the directory\n",
    "\n",
    "files = glob.glob(os.path.join(base_path, \"batch*_sample*_data.npz\"))\n",
    "\n",
    "for file_path in files:\n",
    "    # Extract batch and sample numbers from filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    batch_idx = int(filename.split('_')[0].replace('batch', ''))\n",
    "    \n",
    "    sample_idx = int(filename.split('_')[1].replace('sample', ''))\n",
    "    \n",
    "    # Load the data\n",
    "    data = np.load(file_path)\n",
    "    src_pcd = data['src_pcd']\n",
    "    src_pcd_pred = data['xyz']\n",
    "    unique_points = np.unique(src_pcd_pred, axis=0)\n",
    "    print(f\"Number of unique points: {len(unique_points)}, Total points: {len(src_pcd_pred)}\")\n",
    "    #FPS on src_pcd_inter to get 512 points\n",
    "    pcd_inter = o3d.geometry.PointCloud()\n",
    "    pcd_inter.points = o3d.utility.Vector3dVector(src_pcd_pred)\n",
    "    if len(src_pcd_pred) > 512:\n",
    "        downsampled_pcd_inter = pcd_inter.farthest_point_down_sample(512)\n",
    "        src_pcd_pred = np.asarray(downsampled_pcd_inter.points)\n",
    "    else:\n",
    "        src_pcd_pred = np.asarray(pcd_inter.points)\n",
    "        repeats_needed = int(np.ceil(512 / len(src_pcd_pred)))\n",
    "        src_pcd_pred = np.tile(src_pcd_pred, (repeats_needed, 1))[:512]\n",
    "    \n",
    "    print(f\"Visualizing batch {batch_idx}, sample {sample_idx}\")\n",
    "    #src_pcd_normal = cal_normal(src_pcd_pred)\n",
    "    visualize_comparison(src_pcd, src_pcd_pred, batch_idx, sample_idx)\n",
    "    \n",
    "    # Optional: wait for user input before showing next visualization\n",
    "    #input(\"Press Enter to continue to next sample...\")\n",
    "    \n",
    "    # # Prepare data for saving in the desired format\n",
    "    # output_data = {\n",
    "    #     \"src_pcd\": src_pcd_pred,  # Use processed 'src_pcd_inter' as 'src_pcd'\n",
    "    #     \"src_pcd_normal\": src_pcd_normal,\n",
    "    #     \"model_pcd\": data['model_pcd'],\n",
    "    #     \"model_pcd_normal\": data['model_pcd_normal'],\n",
    "    #     \"model_pcd_transformed\": data['model_pcd_transformed'],\n",
    "    #     \"transform_gt\": data['transform_gt']\n",
    "    # }\n",
    "    \n",
    "    # Construct the output file path in data_dir\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save the modified data to the new file\n",
    "    # print(f\"Saving modified data to {output_file_path}\")\n",
    "    # np.savez(output_file_path, **output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "data_dir = '/home/ali/Documents/robotic_picker/data/'\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "dataset_files = glob.glob(os.path.join(data_dir, 'processed_dataset_*.npz'))\n",
    "print(f'Found {len(dataset_files)} processed dataset files')\n",
    "# Function to compute chamfer distance\n",
    "def compute_chamfer_distance(points1, points2):\n",
    "# Convert to float32 for faster computation\n",
    "    points1 = points1.astype(np.float32)\n",
    "    points2 = points2.astype(np.float32)\n",
    "            \n",
    "            # Create point clouds\n",
    "    pcd1 = o3d.geometry.PointCloud()\n",
    "    pcd2 = o3d.geometry.PointCloud()\n",
    "    pcd1.points = o3d.utility.Vector3dVector(points1)\n",
    "    pcd2.points = o3d.utility.Vector3dVector(points2)\n",
    "            \n",
    "            # Compute distances\n",
    "    dist1 = np.asarray(pcd1.compute_point_cloud_distance(pcd2))\n",
    "    dist2 = np.asarray(pcd2.compute_point_cloud_distance(pcd1))\n",
    "            \n",
    "    return np.mean(dist1) + np.mean(dist2)\n",
    "            \n",
    "def load_and_visualize_processed_file(file_index):\n",
    "    \"\"\"\n",
    "    Load and visualize a processed dataset file\n",
    "    Args:\n",
    "        file_index (int): The index of the file to load\n",
    "    \"\"\"\n",
    "    # Construct file path\n",
    "    file_path = os.path.join(data_dir, f'processed_dataset_{file_index}.npz')\n",
    "    \n",
    "    # Load the data\n",
    "    data = np.load(file_path)\n",
    "    model_pcd = data['model_pcd'].copy()\n",
    "    src_pcd = data['src_pcd'].copy()\n",
    "    transform_gt = data['transform_gt'].copy()\n",
    "    \n",
    "    # Add homogeneous coordinate for visualization\n",
    "    transform_gt_4x4 = np.vstack([transform_gt, np.array([0, 0, 0, 1])])\n",
    "\n",
    "    # Try different mirror transformations and compute chamfer distance\n",
    "    # Define mirror transformations\n",
    "    mirror_matrices = {\n",
    "        'no_mirror': np.eye(4),\n",
    "        'mirror_y': np.array([\n",
    "        [-1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "        ]),\n",
    "        'mirror_z': np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "        ]),\n",
    "        'mirror_yz': np.array([\n",
    "        [-1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    best_distance = float('inf')\n",
    "    best_transform = None\n",
    "    best_transform_name = 'no_mirror'\n",
    "    \n",
    "    # Try each mirror transformation\n",
    "    for mirror_name, mirror_matrix in mirror_matrices.items():\n",
    "        # Apply mirroring to the transformation\n",
    "        test_transform = mirror_matrix @ transform_gt_4x4\n",
    "        \n",
    "        # Transform points for comparison\n",
    "        ones = np.ones((src_pcd.shape[0], 1))\n",
    "        model_points_h = np.hstack((src_pcd, ones))\n",
    "        transformed_points = (test_transform @ model_points_h.T).T[:, :3]\n",
    "        \n",
    "        # Compute chamfer distance\n",
    "        distance = compute_chamfer_distance(transformed_points, model_pcd)\n",
    "        print(f'{mirror_name}: {distance}')\n",
    "        \n",
    "        # Update if this is the best transformation so far\n",
    "        if distance < best_distance:\n",
    "            best_distance = distance\n",
    "            best_transform_name = mirror_name\n",
    "            best_transform = test_transform\n",
    "    \n",
    "    # Use the best transformation\n",
    "    transform_gt_4x4 = best_transform\n",
    "    print(f'Best mirror transformation: {best_transform_name}')\n",
    "    \n",
    "    model_points = np.array(data['model_pcd'])\n",
    "    ones = np.ones((model_points.shape[0], 1))\n",
    "    filtered_points_h = np.hstack((model_points, ones))\n",
    "    model_transformed = (np.linalg.inv(transform_gt_4x4) @ filtered_points_h.T).T[:, :3]\n",
    "\n",
    "    #visualize_sample(model_transformed, src_pcd, np.eye(4))\n",
    "\n",
    "    \n",
    "    # Save the processed data with the new transformation (removing the last row)\n",
    "    input_data = {\n",
    "        \"src_pcd\": data['src_pcd'],\n",
    "        \"src_pcd_normal\": data['src_pcd_normal'],\n",
    "        'model_pcd_transformed': model_transformed,\n",
    "        \"model_pcd\": data['model_pcd'],\n",
    "        \"model_pcd_normal\": data['model_pcd_normal'],\n",
    "        'transform_gt': transform_gt_4x4[:3],  # Remove the last row\n",
    "    }\n",
    "    \n",
    "    # Save processed data with sample ID\n",
    "    output_path = os.path.join(data_dir, f'processed_dataset_{file_index}.npz')\n",
    "    print(f'Saving processed data to {output_path}')\n",
    "    np.savez(output_path, **input_data)\n",
    "        \n",
    "    # Example usage:\n",
    "# Process all files in the dataset\n",
    "for file_index in range(len(dataset_files)):  # Since there are 211 files based on the dataset length\n",
    "    print(f\"\\nProcessing file {file_index}\")\n",
    "    load_and_visualize_processed_file(file_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import glob, os\n",
    "\n",
    "data_dir = '/home/ali/Documents/robotic_picker/data/predictions'\n",
    "# Get list of processed dataset files\n",
    "processed_files = glob.glob(os.path.join(data_dir, '*.npy'))\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "inputs = []\n",
    "models = []\n",
    "H_preds = []\n",
    "H_gts = []\n",
    "\n",
    "i = 0\n",
    "for file_path in processed_files:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    # Load the NPY file with allow_pickle=True\n",
    "    data = np.load(file_path, allow_pickle=True).item()  # Convert to dictionary\n",
    "    loaded_points = data['src_pcd']\n",
    "    H_pred = data['H_pred']  # Use predicted transformation\n",
    "    H_gt = data['H_gt']  # Use ground truth transformation\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "    inputs.append(loaded_points)\n",
    "    models.append(data['model_pcd'])\n",
    "    H_preds.append(H_pred)\n",
    "    H_gts.append(H_gt)\n",
    "    print(H_gt.shape, H_pred.shape)\n",
    "\n",
    "    # if count == 0:\n",
    "    #     H_gt = np.vstack([H_gt, np.array([0, 0, 0, 1])])      \n",
    "        \n",
    "    #     H_offset = H_pred @ np.linalg.inv(H_gt)\n",
    "        \n",
    "    #     H_offset_inv = np.linalg.inv(H_offset)\n",
    "\n",
    "    \n",
    "        \n",
    "    # H_pred = H_offset_inv @ H_pred \n",
    "\n",
    "    # Extract translations from transformation matrices\n",
    "    # Convert to 4x4 matrices by adding homogeneous row\n",
    "    H_gt_4x4 = np.vstack([H_gt, np.array([0, 0, 0, 1])])\n",
    "   \n",
    "    \n",
    "    # Calculate inverses\n",
    "    H_gt_inv = np.linalg.inv(H_gt_4x4)\n",
    "    H_pred_inv = np.linalg.inv(H_pred)\n",
    "    \n",
    "    # Extract translations from inverse transformations\n",
    "    trans_pred = H_pred_inv[:3, 3]\n",
    "    trans_gt = H_gt_inv[:3, 3]\n",
    "\n",
    "    # Calculate translation error in cm and round to 2 decimal places\n",
    "    trans_error_cm = np.round(np.linalg.norm(trans_pred - trans_gt) * 100, 2)\n",
    "    print(f\"Translation error: {trans_error_cm} cm\")\n",
    "\n",
    "    # if count == 100:\n",
    "    #     visualize_sample(data['model_pcd'], loaded_points, H_pred)\n",
    "    \n",
    "    count+=1\n",
    "   \n",
    "    # prompt to break\n",
    "    # input(\"Press Enter to continue...\")\n",
    "    # if input(\"Press Enter to continue...\") == 'q':\n",
    "    #     break\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, open3d as o3d\n",
    "\n",
    "model = 'strawberry_fruit_sampled_no_leave.xyz'\n",
    "# Load points from the file\n",
    "orig_points = []\n",
    "with open(model, 'r') as file:\n",
    "    for line in file:\n",
    "        x_str, y_str, z_str = line.strip().split()\n",
    "        orig_points.append((float(x_str), float(y_str), float(z_str)))\n",
    "\n",
    "# Function to compute chamfer distance\n",
    "def compute_chamfer_distance(points1, points2):\n",
    "# Convert to float32 for faster computation\n",
    "    points1 = points1.astype(np.float32)\n",
    "    points2 = points2.astype(np.float32)\n",
    "            \n",
    "            # Create point clouds\n",
    "    pcd1 = o3d.geometry.PointCloud()\n",
    "    pcd2 = o3d.geometry.PointCloud()\n",
    "    pcd1.points = o3d.utility.Vector3dVector(points1)\n",
    "    pcd2.points = o3d.utility.Vector3dVector(points2)\n",
    "            \n",
    "            # Compute distances\n",
    "    dist1 = np.asarray(pcd1.compute_point_cloud_distance(pcd2))\n",
    "    dist2 = np.asarray(pcd2.compute_point_cloud_distance(pcd1))\n",
    "    return np.mean(dist1) + np.mean(dist2)\n",
    "\n",
    "                            \n",
    "def visualize_sample_prediction(strawberry_model_pcd, observation_pcd, H_pred, H_gt):\n",
    "    filtered_points = np.array(strawberry_model_pcd)\n",
    "    ones = np.ones((filtered_points.shape[0], 1))\n",
    "    filtered_points_h = np.hstack((filtered_points, ones))\n",
    "    ground_truth_transformered = (H_gt @ filtered_points_h.T).T[:, :3]\n",
    "    prediction_transformered = (H_pred @ filtered_points_h.T).T[:, :3]\n",
    "\n",
    "    # Calculate and print centroids\n",
    "    gt_centroid = np.mean(ground_truth_transformered, axis=0)\n",
    "    pred_centroid = np.mean(prediction_transformered, axis=0)\n",
    "    centroid_error = np.linalg.norm(gt_centroid - pred_centroid)\n",
    "    print(f\"Ground truth centroid: {gt_centroid}\")\n",
    "    print(f\"Prediction centroid: {pred_centroid}\")\n",
    "    print(f\"Centroid difference: {centroid_error:.3f}m\")\n",
    "\n",
    "    # Calculate rotation error\n",
    "    R_gt = H_gt[:3, :3]\n",
    "    R_pred = H_pred[:3, :3]\n",
    "    \n",
    "    # Calculate rotation error using matrix multiplication\n",
    "    R_error = R_gt @ R_pred.T\n",
    "    \n",
    "    # Convert rotation matrix to angle-axis representation\n",
    "    angle = np.arccos((np.trace(R_error) - 1) / 2)\n",
    "    rotation_error = np.degrees(angle)\n",
    "    \n",
    "    # Handle numerical instabilities\n",
    "    if np.isnan(rotation_error):\n",
    "        rotation_error = 0.0\n",
    "    \n",
    "    # Calculate translation error\n",
    "    trans_gt = H_gt[:3, 3]\n",
    "    trans_pred = H_pred[:3, 3]\n",
    "    translation_error = np.linalg.norm(trans_gt - trans_pred)\n",
    "    \n",
    "\n",
    "    print(f\"Rotation error (degrees): {rotation_error:.2f}\")\n",
    "    #Create point clouds and visualization code...\n",
    "    # observation_mesh_pcd = o3d.geometry.PointCloud()\n",
    "    # observation_mesh_pcd.points = o3d.utility.Vector3dVector(observation_pcd)\n",
    "\n",
    "    # prediction_pointcloud = o3d.geometry.PointCloud()\n",
    "    # prediction_pointcloud.points = o3d.utility.Vector3dVector(prediction_transformered)\n",
    "\n",
    "    # gt_pointcloud = o3d.geometry.PointCloud()\n",
    "    # gt_pointcloud.points = o3d.utility.Vector3dVector(ground_truth_transformered)\n",
    "\n",
    "    # vis = o3d.visualization.Visualizer()\n",
    "    # vis.create_window()\n",
    "\n",
    "    # observation_mesh_pcd.paint_uniform_color([1, 0, 0])\n",
    "    # prediction_pointcloud.paint_uniform_color([0, 0, 1])\n",
    "    # gt_pointcloud.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "    # vis.add_geometry(observation_mesh_pcd)\n",
    "    # vis.add_geometry(prediction_pointcloud)\n",
    "    \n",
    "\n",
    "    # vis.run()\n",
    "    # vis.destroy_window()\n",
    "    #vis.add_geometry(gt_pointcloud)    \n",
    "\n",
    "    \n",
    "    return centroid_error, rotation_error, translation_error\n",
    "\n",
    "    \n",
    "centroid_errors = []\n",
    "rotation_errors = []\n",
    "translation_errors = []\n",
    "for i in range(len(inputs)):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    \n",
    "    H_pred = H_preds[i].copy()\n",
    "    \n",
    "    H_gt = H_gts[i].copy()\n",
    "    H_gt = np.vstack([H_gt, np.array([0, 0, 0, 1])])\n",
    "   \n",
    "    src_pcd = inputs[i].copy()\n",
    "    \n",
    "    \n",
    "    # # Extract translation from H_pred\n",
    "    # translation = H_pred[:3, 3].copy()\n",
    "\n",
    "    # # Define rotation angles to try (in degrees)\n",
    "    # angles = np.linspace(0, 360, int(37*2))  # every 10 degrees\n",
    "    \n",
    "    \n",
    "    # # Convert inputs[i] to homogeneous coordinates\n",
    "    # observation_points = np.array(inputs[i].copy())\n",
    "\n",
    "\n",
    "    # orig_points = np.array(orig_points)\n",
    "    # ones = np.ones((orig_points.shape[0], 1))\n",
    "    # orig_points_h = np.hstack((orig_points, ones))\n",
    "\n",
    "    # best_distance = float('inf')\n",
    "    # best_mirrored_H = H_pred.copy()\n",
    "    \n",
    "\n",
    "    # mirror_matrices = {\n",
    "    #     'no_mirror': np.eye(4),\n",
    "    #     'mirror_y': np.array([\n",
    "    #     [-1, 0, 0, 0],\n",
    "    #     [0, 1, 0, 0],\n",
    "    #     [0, 0, 1, 0],\n",
    "    #     [0, 0, 0, 1]\n",
    "    #     ]),\n",
    "    #     'mirror_z': np.array([\n",
    "    #     [1, 0, 0, 0],\n",
    "    #     [0, 1, 0, 0],\n",
    "    #     [0, 0, -1, 0],\n",
    "    #     [0, 0, 0, 1]\n",
    "    #     ]),\n",
    "    #     'mirror_yz': np.array([\n",
    "    #     [-1, 0, 0, 0],\n",
    "    #     [0, 1, 0, 0],\n",
    "    #     [0, 0, -1, 0],\n",
    "    #     [0, 0, 0, 1]\n",
    "    #     ])\n",
    "    # }\n",
    "    \n",
    "    # best_distance = float('inf')\n",
    "    # best_transform = None\n",
    "    # best_transform_name = 'no_mirror'\n",
    "    \n",
    "    # # Try each mirror transformation\n",
    "    # for mirror_name, mirror_matrix in mirror_matrices.items():\n",
    "    #     # Apply mirroring to the transformation\n",
    "    #     test_transform = mirror_matrix @ H_pred\n",
    "        \n",
    "    #     # Transform points for comparison\n",
    "    #     ones = np.ones((src_pcd.shape[0], 1))\n",
    "    #     model_points_h = np.hstack((src_pcd, ones))\n",
    "    #     transformed_points = (test_transform @ model_points_h.T).T[:, :3]\n",
    "        \n",
    "    #     # Compute chamfer distance\n",
    "    #     distance = compute_chamfer_distance(transformed_points, orig_points)\n",
    "    #     print(f'{mirror_name}: {distance}')\n",
    "        \n",
    "    #     # Update if this is the best transformation so far\n",
    "    #     if distance < best_distance:\n",
    "    #         best_distance = distance\n",
    "    #         best_transform_name = mirror_name\n",
    "    #         best_transform = test_transform\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    # print(f\"Best chamfer distance: {best_distance}\")\n",
    "    # print(f\"Best mirror transformation: {best_transform_name}\")\n",
    "\n",
    "    # # Update H_pred with the best mirrored transformation\n",
    "    # H_pred = best_mirrored_H\n",
    "    \n",
    "    print(H_pred.shape, H_gt.shape)\n",
    "\n",
    "\n",
    "\n",
    "    H_pred = np.linalg.inv(H_pred)\n",
    "    H_gt = np.linalg.inv(H_gt)\n",
    "   \n",
    "    centroid_error, rotation_error, translation_error = visualize_sample_prediction(\n",
    "        orig_points, src_pcd, \n",
    "        H_pred, H_gt\n",
    "    )\n",
    "    \n",
    "    centroid_errors.append(centroid_error)\n",
    "    rotation_errors.append(rotation_error)\n",
    "    translation_errors.append(translation_error)\n",
    "    \n",
    "    # Calculate success rates for different thresholds\n",
    "\n",
    "translation_thresholds = [0.02, 0.02, 0.01, 0.01]  # in meters\n",
    "rotation_thresholds = [20, 10, 20, 10]  # in degrees\n",
    "\n",
    "for t_threshold, r_threshold in zip(translation_thresholds, rotation_thresholds):\n",
    " # Count samples within both thresholds\n",
    "    num_within_threshold = sum(1 for t, r in zip(translation_errors, rotation_errors) \n",
    "        if t < t_threshold and r < r_threshold)\n",
    "        \n",
    "        # Calculate percentage\n",
    "    percentage_within_threshold = (num_within_threshold / len(translation_errors)) * 100\n",
    "        \n",
    "    print(f\"Success rate for ({t_threshold*100}cm, {r_threshold}°): {percentage_within_threshold:.2f}%\")\n",
    "\n",
    "print(f\"Centroid Error: {centroid_error:.4f}m, Rotation Error: {rotation_error:.2f} degrees, Translation Error: {translation_error*100:.2f} cm\")\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(models[0].shape)\n",
    "print(f\"Average centroid error: {np.mean(centroid_errors):.3f}m\")\n",
    "print(f\"Average rotation error: {np.mean(rotation_errors):.2f} degrees\")\n",
    "print(f\"Average translation error: {np.mean(translation_errors) * 10:.3f}cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_orig_strawberry_points = []\n",
    "orig_strawberry_points = []\n",
    "import numpy as np\n",
    "\n",
    "with open('/home/ali/Downloads/strawberry_fruit_sampled.xyz', 'r') as file:\n",
    "    for line in file:\n",
    "        x_str, y_str, z_str = line.strip().split()\n",
    "        r_orig_strawberry_points.append((float(x_str), float(y_str), float(z_str)))\n",
    "\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "points1 = np.array(r_orig_strawberry_points)\n",
    "points2 = np.array(orig_strawberry_points)\n",
    "\n",
    "# Create rotation matrix for 90 degrees around x-axis\n",
    "rotation_x = o3d.geometry.get_rotation_matrix_from_xyz([np.pi/2, 0, 0])\n",
    "\n",
    "# Rotate points2\n",
    "points2_rotated = points2 @ rotation_x.T\n",
    "\n",
    "# Visualize both point clouds\n",
    "visualize_sample(points1, points2_rotated, np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "def segment_points(masks_list, points_reshaped):\n",
    "    filtered_points = {}\n",
    "    for i, mask in enumerate(masks_list):\n",
    "        mask_bool = mask > 0\n",
    "        filtered = points_reshaped[mask_bool]\n",
    "        if len(filtered) > 0:\n",
    "            # Compute centroid and distances to it\n",
    "            print(f\"number of segmented points {len(filtered)}\")\n",
    "            centroid = np.mean(filtered, axis=0)\n",
    "            distances = np.linalg.norm(filtered - centroid, axis=1)\n",
    "            # Use median absolute deviation to set a robust threshold\n",
    "            median_dist = np.median(distances)\n",
    "            mad = np.median(np.abs(distances - median_dist))\n",
    "            # Set threshold as median + 3 * MAD (avoid zero MAD)\n",
    "            threshold = median_dist + 3 * (mad if mad > 0 else 1e-6)\n",
    "            # Keep only inliers that are not too far from the centroid\n",
    "            inliers = filtered[distances <= threshold]\n",
    "            print(f\"number of inliers {len(inliers)}\")\n",
    "            if len(inliers) > 0:\n",
    "                filtered_points[i] = inliers\n",
    "\n",
    "    return filtered_points\n",
    "\n",
    "\n",
    "\n",
    "def segment_pointcloud(frame, points):\n",
    "    # yolo setup\n",
    "    model_path = 'yolo_model.pt'\n",
    "    yolo_model = YOLO(model_path)\n",
    "\n",
    "    # sam2 setup        \n",
    "    checkpoint =  \"sam2_hiera_small.pt\"\n",
    "    model_cfg = \"sam2_hiera_s.yaml\"\n",
    "    predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))\n",
    "    # YOLO detection and SAM2 segmentation (using existing code)\n",
    "    results = yolo_model.track(source=frame, persist=True, conf=0.6, verbose=False)\n",
    "    if results[0].boxes.id is None:\n",
    "        print(\"No object detected\")\n",
    "    else:\n",
    "        masks_list = []\n",
    "        bboxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "        ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "        confidences = results[0].boxes.conf.cpu().numpy().astype(float)\n",
    "\n",
    "        with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            predictor.set_image(frame)\n",
    "            for box in bboxes:\n",
    "                input_box = np.array(box).reshape(1, 4)            \n",
    "                masks, _, _ = predictor.predict(box=input_box, multimask_output=False)\n",
    "                mask = (masks > 0).astype(np.uint8) * 255\n",
    "                masks_list.append(mask[0])\n",
    "\n",
    "        # Visualize segmented image\n",
    "        visualization_frame = frame.copy()\n",
    "        for mask in masks_list:\n",
    "            # Apply mask overlay on the image\n",
    "            colored_mask = np.zeros_like(frame)\n",
    "            colored_mask[mask > 0] = [0, 255, 0]  # Green overlay\n",
    "            visualization_frame = cv2.addWeighted(visualization_frame, 1, colored_mask, 0.5, 0)\n",
    "        \n",
    "\n",
    "        # Filter and visualize point cloud\n",
    "        print(f\"masks_list len: {len(masks_list)}\")\n",
    "        points_reshaped = points.reshape(480, 640, 3)\n",
    "        #filtered_points = np.zeros_like(points_reshaped)\n",
    "        filtered_points = segment_points(masks_list, points_reshaped)\n",
    "        # for mask in masks_list:\n",
    "        #     print(\"loop start\")\n",
    "        #     # Reshape points to match image dimensions (480, 640, 3)\n",
    "            \n",
    "            \n",
    "        #     # Get points corresponding to the mask\n",
    "            \n",
    "        #     if 'filtered_points' not in locals():\n",
    "        #         filtered_points = points_reshaped[mask > 0]\n",
    "        #     else:\n",
    "        #         filtered_points = np.vstack((filtered_points, points_reshaped[mask > 0]))\n",
    "        return filtered_points\n",
    "            \n",
    "# Get all files from both directories\n",
    "rgb_dir = \"/home/netbot/Documents/Malak/Intel Realsense/strawberry_extracted_rgb\"\n",
    "pointcloud_dir = \"/home/netbot/Documents/Malak/Intel Realsense/strawberry_extracted_pointcloud\"\n",
    "segmented_pcl_dir=\"/home/netbot/Documents/Malak/sam2/sam2/segmented_pointcloud\"\n",
    "\n",
    "rgb_files = sorted(glob.glob(os.path.join(rgb_dir, \"*.png\")))\n",
    "pointcloud_files = sorted(glob.glob(os.path.join(pointcloud_dir, \"*.txt\")))\n",
    "\n",
    "# Process each pair of files\n",
    "for rgb_file, pc_file in zip(rgb_files, pointcloud_files):\n",
    "    # Extract IDs to ensure they match\n",
    "    rgb_id = os.path.basename(rgb_file).split('_')[-1].split('.')[0]\n",
    "    pc_id = os.path.basename(pc_file).split('_')[-1].split('.')[0]\n",
    "    \n",
    "    if rgb_id == pc_id:\n",
    "        # Load the files\n",
    "        frame = cv2.imread(rgb_file)\n",
    "        points = np.loadtxt(pc_file)\n",
    "        \n",
    "        # Process the files\n",
    "        filtered_points = segment_pointcloud(frame, points)\n",
    "        \n",
    "        # For each segmented point cloud in the dictionary\n",
    "        for pcd_id, points in filtered_points.items():\n",
    "            # Create point cloud object\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(points)\n",
    "            \n",
    "            # Create unique filename using scene_id and point cloud id\n",
    "            output_file = os.path.join(segmented_pcl_dir, f\"segmented_{pc_id}_{pcd_id}.ply\")\n",
    "            \n",
    "            # Save the segmented point cloud\n",
    "            o3d.io.write_point_cloud(output_file, pcd)\n",
    "            \n",
    "            # Optionally visualize each point cloud\n",
    "            # o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "orig_strawberry_points = []\n",
    "strawberry_model_pcd = '/home/ali/Downloads/strawberry_fruit_sampled.xyz'\n",
    "with open(strawberry_model_pcd, 'r') as file:\n",
    "        for line in file:\n",
    "                x_str, y_str, z_str = line.strip().split()\n",
    "                orig_strawberry_points.append((float(x_str), float(y_str), float(z_str)))\n",
    "\n",
    "points_array = np.array(orig_strawberry_points)\n",
    "# Remove the top part of y-axis (e.g. leaves) by keeping only points with y lower than a threshold\n",
    "threshold = 0.016  # adjust the threshold value as needed\n",
    "filtered_points = points_array[points_array[:, 1] < threshold]\n",
    "\n",
    "# Additional filtering based on a plane (only for points with negative x and positive y)\n",
    "# The plane is assumed to be tilted around z with the following parameters:\n",
    "#   Plane equation: y = tan(angle) * x + offset\n",
    "#   Points that lie above this plane (i.e., y value greater than the plane value) will be removed.\n",
    "plane_angle_deg = 90 # angle in degrees (editable)\n",
    "plane_angle = np.deg2rad(plane_angle_deg)\n",
    "plane_offset = 0.020   # offset along y-axis (editable)\n",
    "slope = np.tan(plane_angle)\n",
    "\n",
    "# Create a mask to keep points\n",
    "# Only apply this filter for points in the quadrant: x < 0 and y > 0.\n",
    "mask = np.ones(filtered_points.shape[0], dtype=bool)\n",
    "for i, (x, y, z) in enumerate(filtered_points):\n",
    "        if x < 0 and y > 0:\n",
    "                if y > (slope * x + plane_offset):\n",
    "                        mask[i] = False\n",
    "\n",
    "final_points = filtered_points[mask]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Plane angle (degrees):\", plane_angle_deg)\n",
    "print(\"Plane offset:\", plane_offset)\n",
    "# Clone points with positive y by rotating them around the z-axis\n",
    "positive_y_mask = final_points[:, 1] > 0\n",
    "points_positive_y = final_points[positive_y_mask]\n",
    "\n",
    "#Define a rotation matrix around z (e.g. 180° rotation to mirror these points)\n",
    "theta = np.pi  # 180 degrees in radians\n",
    "Ry = np.array([[np.cos(theta), 0, np.sin(theta)],\n",
    "                           [0, 1, 0],\n",
    "                           [-np.sin(theta), 0, np.cos(theta)]])\n",
    "cloned_points = (Ry @ points_positive_y.T).T\n",
    "\n",
    "# Append the cloned points to final_points\n",
    "final_points = np.vstack([final_points, cloned_points])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(final_points)\n",
    "\n",
    "axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "o3d.visualization.draw_geometries([pcd, axis])\n",
    "\n",
    "np.savetxt('strawberry_fruit_sampled_no_leave.xyz', final_points, fmt='%.8f')\n",
    "print(\"Final points saved as strawberry_fruit_sampled_no_leave.xyz\")\n",
    "print(\"Cloned positive y points around y-axis. Total points:\", final_points.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Path to the xyz file\n",
    "file_path = 'strawberry_fruit_sampled_no_leave.xyz'\n",
    "\n",
    "# Load the point data (assuming the file contains three columns: x, y, z)\n",
    "points = np.loadtxt(file_path)\n",
    "\n",
    "# Create an Open3D PointCloud object and assign the points\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# Optionally, you can estimate normals or set colors, for example:\n",
    "# pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.01, max_nn=30))\n",
    "# pcd.paint_uniform_color([0.1, 0.8, 0.1])  # Greenish color\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial import cKDTree\n",
    " \n",
    "# (Keep existing code to load strawberry model, orig_points, etc.)\n",
    " \n",
    "orig_strawberry_points = []\n",
    "strawberry_model_pcd = 'strawberry_fruit_sampled_no_leave.xyz'\n",
    "with open(strawberry_model_pcd, 'r') as file:\n",
    "    for line in file:\n",
    "        x_str, y_str, z_str = line.strip().split()\n",
    "        orig_strawberry_points.append((float(x_str), float(y_str), float(z_str)))\n",
    "\n",
    "orig_strawberry_points = np.array(orig_strawberry_points)\n",
    "print(\"orig_strawberry_points\", orig_strawberry_points.shape)\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(orig_strawberry_points)\n",
    "\n",
    "# Set model color to red and copy points\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (len(orig_strawberry_points), 1)))\n",
    "orig_points = np.asarray(pcd.points).copy()\n",
    "\n",
    "# Load an initial partial point cloud\n",
    "partial_pcd = o3d.io.read_point_cloud(\"segmented_real_pointcloud/segmented_0002_0.ply\")\n",
    "partial_points = np.asarray(partial_pcd.points)\n",
    "partial_pcd.colors = o3d.utility.Vector3dVector(np.tile([0, 0, 1], (partial_points.shape[0], 1)))\n",
    "\n",
    "# --- Transformation: Align pcd points to the centroid of partial_pcd and rotate around x by 90 degrees ---\n",
    "\n",
    "# Compute centroids of the strawberry model and the current partial point cloud.\n",
    "strawberry_centroid = np.mean(orig_strawberry_points, axis=0)\n",
    "partial_centroid = np.mean(partial_points, axis=0)\n",
    "\n",
    "# Calculate translation needed to align the strawberry centroid to the partial centroid.\n",
    "tx, ty, tz = partial_centroid - strawberry_centroid\n",
    "\n",
    "# Define rotation angles in degrees; here, 90 degrees around the x-axis.\n",
    "rx, ry, rz = 90, 0, 0\n",
    "\n",
    "# Generate the rotation matrix for the given angles.\n",
    "R = o3d.geometry.get_rotation_matrix_from_xyz((np.deg2rad(rx), np.deg2rad(ry), np.deg2rad(rz)))\n",
    "\n",
    "# Apply the rotation followed by the translation to the strawberry points.\n",
    "transformed_points = (R @ orig_strawberry_points.T).T + np.array([tx, ty, tz])\n",
    "pcd.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    "\n",
    "print(\"Applied translation (tx, ty, tz):\", (tx, ty, tz))\n",
    "print(\"Applied rotation (rx, ry, rz in degrees):\", (rx, ry, rz))\n",
    "\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    " \n",
    "pcd_display = o3d.geometry.PointCloud()\n",
    "pcd_display.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "pcd_display.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    " \n",
    "# Create a global visualizer (initial title will be used for the first partial)\n",
    "vis = o3d.visualization.Visualizer()\n",
    "# vis.create_window(\"Visualizer - segmented_0000_0\", width=960, height=1080, left=2000, top=10)\n",
    "vis.create_window(\"Visualizer - segmented_0000_0\", width=1920, height=2160, left=2000)\n",
    "vis.add_geometry(pcd_display)\n",
    "vis.add_geometry(partial_pcd)\n",
    "#vis.add_geometry(coordinate_frame)\n",
    " \n",
    "transformation = np.eye(4)\n",
    " \n",
    "def apply_transformation():\n",
    "    global transformation, pcd_display\n",
    "    tx = slider_tx.get()\n",
    "    ty = slider_ty.get()\n",
    "    tz = slider_tz.get()\n",
    "    rx = np.deg2rad(slider_rx.get())\n",
    "    ry = np.deg2rad(slider_ry.get())\n",
    "    rz = np.deg2rad(slider_rz.get())\n",
    "    R = o3d.geometry.get_rotation_matrix_from_xyz((rx, ry, rz))\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = [tx, ty, tz]\n",
    "    transformation = T\n",
    "    transformed_points = (R @ orig_points.T).T + np.array([tx, ty, tz])\n",
    "    pcd_display.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "    pcd_display.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    "    vis.update_geometry(pcd_display)\n",
    "    print(\"Applied transformation:\\n\", T)\n",
    " \n",
    "\n",
    "def move_to_centroid():\n",
    "    # Compute initial guess.\n",
    "    strawberry_centroid = np.mean(orig_points, axis=0)\n",
    "    partial_centroid = np.mean(partial_points, axis=0)\n",
    "    translation_init = partial_centroid - strawberry_centroid\n",
    "    init_tx, init_ty, init_tz = translation_init\n",
    "    init_rx, init_ry, init_rz = np.deg2rad(90), 0, 0\n",
    "\n",
    "    \n",
    "\n",
    "    # Define the objective function (Chamfer distance with a z-penalty).\n",
    "    def chamfer_distance(params):\n",
    "        tx, ty, tz, rx, ry, rz = params\n",
    "        R = o3d.geometry.get_rotation_matrix_from_xyz((rx, ry, rz))\n",
    "        transformed = (R @ orig_points.T).T + np.array([tx, ty, tz])\n",
    "        tree_partial = cKDTree(partial_points)\n",
    "        dists1, _ = tree_partial.query(transformed)\n",
    "        tree_trans = cKDTree(transformed)\n",
    "        dists2, _ = tree_trans.query(partial_points)\n",
    "        chamfer = np.mean(dists1**2) + np.mean(dists2**2)\n",
    "        penalty = 1000 * ((tz - init_tz)**2)  # Strongly penalize z shift\n",
    "        return chamfer + penalty\n",
    "    \n",
    "    # Run optimization starting from the initial guess.\n",
    "    x0 = [init_tx, init_ty, init_tz, init_rx, init_ry, init_rz]\n",
    "    res = minimize(chamfer_distance, x0, method='Nelder-Mead', options={'maxiter': 100})\n",
    "    optimal = res.x\n",
    "    print(\"Optimization result:\", optimal)\n",
    "\n",
    "    slider_tx.set(optimal[0])\n",
    "    slider_ty.set(optimal[1])\n",
    "    slider_tz.set(optimal[2])\n",
    "    slider_rx.set(np.rad2deg(optimal[3]))\n",
    "    slider_ry.set(np.rad2deg(optimal[4]))\n",
    "    slider_rz.set(np.rad2deg(optimal[5]))\n",
    " \n",
    "    apply_transformation()\n",
    "    print(\"Moved strawberry model to partial pointcloud's centroid.\")\n",
    " \n",
    "def save_transformation():\n",
    "    current_filename=os.path.basename(partial_files[partial_index-1])\n",
    "    identifier = current_filename.replace(\"segmented_\", \"\").replace(\".ply\", \"\")\n",
    "    \n",
    "    os.makedirs(\"transformation_matrix\", exist_ok=True)\n",
    "    np.save(f\"transformation_matrix/transformation_matrix_{identifier}.npy\", transformation)\n",
    "    transformed_points = (transformation[:3, :3] @ orig_points.T).T + transformation[:3, 3]\n",
    "    pcd_save = o3d.geometry.PointCloud()\n",
    "    pcd_save.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "    pcd_save.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    "    os.makedirs(\"transformation_strawberry_model\", exist_ok=True)\n",
    "    o3d.io.write_point_cloud(f\"transformation_strawberry_model/transformation_strawberry_model_{identifier}.ply\", pcd_save)\n",
    "    print(\"Saved transformation matrix and model for\", identifier)\n",
    " \n",
    "# Process All function remains unchanged\n",
    "def process_all():\n",
    "    folder = \"segmented_real_pointcloud\"\n",
    "    pattern = os.path.join(folder, \"segmented_*.ply\")\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    for filepath in files:\n",
    "        print(\"Processing\", filepath)\n",
    "        current_partial_pcd = o3d.io.read_point_cloud(filepath)\n",
    "        current_points = np.asarray(current_partial_pcd.points)\n",
    "        current_partial_pcd.colors = o3d.utility.Vector3dVector(np.tile([0, 0, 1], (current_points.shape[0], 1)))\n",
    "        global partial_points, partial_pcd\n",
    "        partial_points = current_points\n",
    "        try:\n",
    "            vis.remove_geometry(partial_pcd)\n",
    "        except:\n",
    "            pass\n",
    "        partial_pcd = current_partial_pcd\n",
    "        vis.add_geometry(partial_pcd)\n",
    "        strawberry_centroid = np.mean(orig_points, axis=0)\n",
    "        partial_centroid = np.mean(partial_points, axis=0)\n",
    "        translation = partial_centroid - strawberry_centroid\n",
    "        slider_tx.set(translation[0])\n",
    "        slider_ty.set(translation[1])\n",
    "        slider_tz.set(translation[2])\n",
    "        slider_rx.set(90)\n",
    "        slider_ry.set(0)\n",
    "        slider_rz.set(0)\n",
    "        apply_transformation()\n",
    "       \n",
    "        identifier = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        # identifier = os.path.basename(filename)\n",
    " \n",
    "        save_transformation(identifier)\n",
    "        vis.poll_events()\n",
    " \n",
    "# Create a sorted list of partial pointcloud files and an index for going to the next partial.\n",
    "partial_files = sorted(glob.glob(os.path.join(\"segmented_real_pointcloud\", \"segmented_*.ply\")))\n",
    "partial_index = 1   # Since the first file is already loaded\n",
    " \n",
    "def next_partial():\n",
    "    global partial_files, partial_index, partial_pcd, partial_points, vis\n",
    "    if partial_index >= len(partial_files):\n",
    "        print(\"No more partial pointclouds.\")\n",
    "        return\n",
    "    filename = partial_files[partial_index]\n",
    "    partial_index += 1\n",
    "    print(\"Loading\", filename)\n",
    "    # Read the new partial\n",
    "    new_partial = o3d.io.read_point_cloud(filename)\n",
    "    new_partial_points = np.asarray(new_partial.points)\n",
    "    new_partial.colors = o3d.utility.Vector3dVector(np.tile([0, 0, 1], (new_partial_points.shape[0], 1)))\n",
    "    partial_points = new_partial_points\n",
    "    try:\n",
    "        vis.remove_geometry(partial_pcd)\n",
    "    except:\n",
    "        pass\n",
    "    partial_pcd = new_partial\n",
    "    # Update sliders so that the strawberry model is centered on the partial\n",
    "    strawberry_centroid = np.mean(orig_points, axis=0)\n",
    "    partial_centroid = np.mean(partial_points, axis=0)\n",
    "    translation = partial_centroid - strawberry_centroid\n",
    "    slider_tx.set(translation[0])\n",
    "    slider_ty.set(translation[1])\n",
    "    slider_tz.set(translation[2])\n",
    "    slider_rx.set(90)\n",
    "    slider_ry.set(0)\n",
    "    slider_rz.set(0)\n",
    "    apply_transformation()\n",
    "    # Re-create the visualizer window with the new title (the title now shows the partial file name)\n",
    "    new_title = f\"Visualizer - {os.path.basename(filename)}\"\n",
    " \n",
    "    vis.destroy_window()\n",
    "    vis.create_window(new_title, width=1920, height=2160, left=2000)\n",
    "    vis.add_geometry(pcd_display)\n",
    "    vis.add_geometry(partial_pcd)\n",
    "    vis.add_geometry(coordinate_frame)\n",
    "    print(\"Updated visualizer with new title.\")\n",
    " \n",
    "def update_visualizer():\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    root.after(50, update_visualizer)\n",
    " \n",
    "def create_slider_frame(parent, label_text, slider_from, slider_to, resolution):\n",
    "    frame = tk.Frame(parent)\n",
    "    frame.pack(pady=2)\n",
    "    tk.Label(frame, text=label_text).pack(side=tk.LEFT)\n",
    "    slider = tk.Scale(frame, from_=slider_from, to=slider_to, resolution=resolution,\n",
    "                      orient=tk.HORIZONTAL, length=200, command=lambda x: apply_transformation())\n",
    "    slider.pack(side=tk.LEFT)\n",
    "    btn_minus = tk.Button(frame, text=\"-\", command=lambda: slider.set(slider.get() - resolution))\n",
    "    btn_minus.pack(side=tk.LEFT, padx=2)\n",
    "    btn_plus = tk.Button(frame, text=\"+\", command=lambda: slider.set(slider.get() + resolution))\n",
    "    btn_plus.pack(side=tk.LEFT, padx=2)\n",
    "    return slider\n",
    " \n",
    "root = tk.Tk()\n",
    "root.title(\"Strawberry Transformation\")\n",
    " \n",
    "slider_tx = create_slider_frame(root, \"Translation X\", -1, 1, 0.002)\n",
    "slider_ty = create_slider_frame(root, \"Translation Y\", -1, 1, 0.002)\n",
    "slider_tz = create_slider_frame(root, \"Translation Z\", -1, 1, 0.002)\n",
    "slider_rx = create_slider_frame(root, \"Rotation X (deg)\", -180, 180, 0.5)\n",
    "slider_ry = create_slider_frame(root, \"Rotation Y (deg)\", -180, 180, 0.5)\n",
    "slider_rz = create_slider_frame(root, \"Rotation Z (deg)\", -180, 180, 0.5)\n",
    " \n",
    "btn_move = tk.Button(root, text=\"Move to Centroid\", command=move_to_centroid)\n",
    "btn_move.pack(pady=5)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "btn_save = tk.Button(root, text=\"Save Transformation\", command=lambda: save_transformation())\n",
    "btn_save.pack(pady=5)\n",
    "btn_process_all = tk.Button(root, text=\"Process All Partials\", command=process_all)\n",
    "btn_process_all.pack(pady=5)\n",
    " \n",
    "# New button to go to the next partial pointcloud\n",
    "btn_next = tk.Button(root, text=\"Next Partial\", command=next_partial)\n",
    "btn_next.pack(pady=5)\n",
    " \n",
    "root.after(50, update_visualizer)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the .ply files for output and input\n",
    "ply_directory = \"transformation_strawberry_model\"\n",
    "in_directory = \"segmented_real_pointcloud\"\n",
    "\n",
    "# Get list of output .ply files in the ply_directory\n",
    "ply_files = glob.glob(os.path.join(ply_directory, \"*.ply\"))\n",
    "\n",
    "# Loop through each output file, find the corresponding input file, and visualize both\n",
    "all_points_list = []  # To collect all points for global statistics\n",
    "\n",
    "for out_file in ply_files:\n",
    "    basename = os.path.basename(out_file)\n",
    "    # Expected format: transformation_strawberry_model_0002_0.ply\n",
    "    parts = basename.split('_')\n",
    "    # The identifier is the 4th and 5th parts (e.g., \"0002\" and \"0.ply\")\n",
    "    if len(parts) < 5:\n",
    "        print(f\"Skipping file with unexpected format: {basename}\")\n",
    "        continue\n",
    "    identifier = parts[3] + '_' + parts[4].replace('.ply', '')\n",
    "    in_filename = f\"segmented_{identifier}.ply\"\n",
    "    in_file = os.path.join(in_directory, in_filename)\n",
    "    \n",
    "    if not os.path.exists(in_file):\n",
    "        print(f\"Input file not found for {basename}: expected {in_filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nVisualizing:\\n Output: {out_file}\\n Input: {in_file}\")\n",
    "    in_pcd = o3d.io.read_point_cloud(in_file)\n",
    "    out_pcd = o3d.io.read_point_cloud(out_file)\n",
    "    points = np.asarray(in_pcd.points)\n",
    "    all_points_list.append(points)\n",
    "    \n",
    "    # Compute and print per-file statistics for all axes\n",
    "    mean_vals = np.mean(points, axis=0)\n",
    "    std_vals = np.std(points, axis=0)\n",
    "    print(f\"Stats for {in_filename}:\")\n",
    "    print(f\"  Mean (x,y,z): {mean_vals}\")\n",
    "    print(f\"  Standard deviation (x,y,z): {std_vals}\")\n",
    "    \n",
    "    # # Robust z filtering using median and MAD\n",
    "    # z_vals = points[:, 2]\n",
    "    # z_median = np.median(z_vals)\n",
    "    # mad = np.median(np.abs(z_vals - z_median))\n",
    "    # mad_threshold = 1.5 * mad if mad > 0 else 0.01\n",
    "\n",
    "    # mask = np.abs(z_vals - z_median) < mad_threshold\n",
    "    in_filtered_points = points.copy()\n",
    "    print(f\"  Initial number of points: {in_filtered_points.shape[0]}\")\n",
    "\n",
    "    # Additional filtering step: enforce that the standard deviation in z only is below the target value.\n",
    "    target_std = 0.003\n",
    "    current_std = np.std(in_filtered_points[:, 2])\n",
    "    iter_count = 0\n",
    "    max_iter = 1000\n",
    "    outlier_points = []  # To collect points that got filtered out\n",
    "    print(f\"  Initial std(z): {current_std:.8f}, target std(z): {target_std:.8f}\")\n",
    "    while current_std > target_std and in_filtered_points.shape[0] > 1 and iter_count < max_iter:\n",
    "        # Remove the point with the maximum deviation from the median along z\n",
    "        z_vals_filtered = in_filtered_points[:, 2]\n",
    "        deviation = np.abs(z_vals_filtered - np.median(z_vals_filtered))\n",
    "        remove_index = np.argmax(deviation)\n",
    "        # Save the removed point as an outlier\n",
    "        outlier_points.append(in_filtered_points[remove_index])\n",
    "        in_filtered_points = np.delete(in_filtered_points, remove_index, axis=0)\n",
    "        current_std = np.std(in_filtered_points[:, 2])\n",
    "        iter_count += 1\n",
    "\n",
    "    print(f\"After additional filtering: kept {in_filtered_points.shape[0]} inliers with std(z) = {current_std:.8f}\")\n",
    "\n",
    "    # Create point clouds for visualization with different colors\n",
    "    in_filtered_pcd = o3d.geometry.PointCloud()\n",
    "    in_filtered_pcd.points = o3d.utility.Vector3dVector(in_filtered_points)\n",
    "    in_filtered_pcd.paint_uniform_color([0, 1, 0])  # Green for inliers\n",
    "\n",
    "    outlier_points = np.array(outlier_points)\n",
    "    in_outlier_pcd = o3d.geometry.PointCloud()\n",
    "    if outlier_points.size > 0:\n",
    "        in_outlier_pcd.points = o3d.utility.Vector3dVector(outlier_points)\n",
    "    in_outlier_pcd.paint_uniform_color([1, 0, 0])  # Red for outliers\n",
    "    out_pcd.paint_uniform_color([0, 0, 1])  # Blue for output\n",
    "\n",
    "    # Visualize the filtered inliers and the removed outliers together.\n",
    "    o3d.visualization.draw_geometries([in_filtered_pcd, out_pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "import open3d as o3d\n",
    "model_path = 'yolo_model.pt'\n",
    "yolo_model = YOLO(model_path)\n",
    "# sam2 setup        \n",
    "checkpoint =  \"sam2_hiera_small.pt\"\n",
    "model_cfg = \"sam2_hiera_s.yaml\"\n",
    "predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))\n",
    "\n",
    "def segment_pointcloud(frame, points):\n",
    "    # YOLO detection and SAM2 segmentation (using existing code)\n",
    "    results = yolo_model.predict(source=frame, conf=0.6, verbose=True)\n",
    "    if len(results[0].boxes) == 0:\n",
    "        print(\"No object detected\")\n",
    "        return None\n",
    "    else:\n",
    "        masks_list = []\n",
    "        bboxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "        confidences = results[0].boxes.conf.cpu().numpy().astype(float)\n",
    "\n",
    "        with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            predictor.set_image(frame)\n",
    "            for box in bboxes:\n",
    "                input_box = np.array(box).reshape(1, 4)            \n",
    "                masks, _, _ = predictor.predict(box=input_box, multimask_output=False)\n",
    "                mask = (masks > 0).astype(np.uint8) * 255\n",
    "                masks_list.append(mask[0])\n",
    "\n",
    "        # Visualize segmented image\n",
    "        visualization_frame = frame.copy()\n",
    "        for mask in masks_list:\n",
    "            # Apply mask overlay on the image\n",
    "            colored_mask = np.zeros_like(frame)\n",
    "            colored_mask[mask > 0] = [0, 255, 0]  # Green overlay\n",
    "            visualization_frame = cv2.addWeighted(visualization_frame, 1, colored_mask, 0.5, 0)\n",
    "        \n",
    "        # Save the segmented visualization image\n",
    "        cv2.imwrite(\"segmented_visualization.png\", visualization_frame)\n",
    "        print(\"Segmented image saved as segmented_visualization.png\")\n",
    "\n",
    "        # Filter and visualize point cloud\n",
    "        print(f\"masks_list len: {len(masks_list)}\")\n",
    "        points_reshaped = points.reshape(480, 848, 3)\n",
    "        for mask in masks_list:\n",
    "            print(\"loop start\")\n",
    "            if 'filtered_points' not in locals():\n",
    "                filtered_points = points_reshaped[mask > 0]\n",
    "            else:\n",
    "                filtered_points = np.vstack((filtered_points, points_reshaped[mask > 0]))\n",
    "        return filtered_points\n",
    "\n",
    "def extra_filter(points):\n",
    "    if points.shape[0] > 0:\n",
    "        # Compute centroid and distances to it\n",
    "        \n",
    "        centroid = np.mean(points, axis=0)\n",
    "        distances = np.linalg.norm(points - centroid, axis=1)\n",
    "        # Use median absolute deviation to set a robust threshold\n",
    "        median_dist = np.median(distances)\n",
    "        mad = np.median(np.abs(distances - median_dist))\n",
    "            # Set threshold as median + 3 * MAD (avoid zero MAD)\n",
    "        threshold = median_dist + 3 * (mad if mad > 0 else 1e-6)\n",
    "            # Keep only inliers that are not too far from the centroid\n",
    "        inliers = points[distances <= threshold]\n",
    "        print(f\"number of inliers {len(inliers)}\")\n",
    "        if len(inliers) > 0:\n",
    "            filtered_points = inliers.copy()\n",
    "            return filtered_points\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial import cKDTree\n",
    " \n",
    "# (Keep existing code to load strawberry model, orig_points, etc.)\n",
    " \n",
    "orig_strawberry_points = []\n",
    "# strawberry_model_pcd = 'strawberry_fruit_sampled.xyz'\n",
    "strawberry_model_pcd = 'strawberry_fruit_sampled_no_leave.xyz'\n",
    "with open(strawberry_model_pcd, 'r') as file:\n",
    "    for line in file:\n",
    "        x_str, y_str, z_str = line.strip().split()\n",
    "        orig_strawberry_points.append((float(x_str), float(y_str), float(z_str)))\n",
    " \n",
    "orig_strawberry_points =  np.array(orig_strawberry_points)\n",
    "#orig_strawberry_points = orig_strawberry_points[orig_strawberry_points[:, 2] > 0]\n",
    "print(\"orig_strawberry_points\", orig_strawberry_points.shape)\n",
    " \n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(orig_strawberry_points)\n",
    " \n",
    "# Set model color to red and copy points\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (len(orig_strawberry_points), 1)))\n",
    "orig_points = np.asarray(pcd.points).copy()\n",
    " \n",
    "# Load an initial partial point cloud\n",
    "# partial_pcd = o3d.io.read_point_cloud(\"segmented_pointcloud_separated/segmented_0000_0.ply\")\n",
    "# partial_pcd = o3d.io.read_point_cloud(\"front_orientation3_separated/segmented_0000_0.ply\")\n",
    "partial_pcd = o3d.io.read_point_cloud(\"data/segmented/filtered_points_0202_detection_0.ply\")\n",
    "# partial_points = np.load(\"filtered_points2.npy\")\n",
    "# partial_pcd = o3d.geometry.PointCloud()\n",
    "# partial_pcd.points = o3d.utility.Vector3dVector(partial_points)\n",
    "\n",
    "\n",
    "partial_points = np.asarray(partial_pcd.points)\n",
    "partial_pcd.colors = o3d.utility.Vector3dVector(np.tile([0, 0, 1], (partial_points.shape[0], 1)))\n",
    " \n",
    "# --- Transformation: Align pcd points to the centroid of partial_pcd and rotate around x by 90 degrees ---\n",
    " \n",
    "# Compute centroids of the strawberry model and the current partial point cloud.\n",
    "strawberry_centroid = np.mean(orig_strawberry_points, axis=0)\n",
    "partial_centroid = np.mean(partial_points, axis=0)\n",
    " \n",
    "# Calculate translation needed to align the strawberry centroid to the partial centroid.\n",
    "tx, ty, tz = partial_centroid - strawberry_centroid\n",
    " \n",
    "# Define rotation angles in degrees; here, 90 degrees around the x-axis.\n",
    "rx, ry, rz = 90, 0, 0\n",
    " \n",
    "# Generate the rotation matrix for the given angles.\n",
    "R = o3d.geometry.get_rotation_matrix_from_xyz((np.deg2rad(rx), np.deg2rad(ry), np.deg2rad(rz)))\n",
    " \n",
    "# Apply the rotation followed by the translation to the strawberry points.\n",
    "transformed_points = (R @ orig_strawberry_points.T).T + np.array([tx, ty, tz])\n",
    "pcd.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    " \n",
    "print(\"Applied translation (tx, ty, tz):\", (tx, ty, tz))\n",
    "print(\"Applied rotation (rx, ry, rz in degrees):\", (rx, ry, rz))\n",
    " \n",
    " \n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    " \n",
    "pcd_display = o3d.geometry.PointCloud()\n",
    "pcd_display.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "pcd_display.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    " \n",
    "# Create a global visualizer (initial title will be used for the first partial)\n",
    "vis = o3d.visualization.Visualizer()\n",
    "# vis.create_window(\"Visualizer - segmented_0000_0\", width=960, height=1080, left=2000, top=10)\n",
    "vis.create_window(\"Visualizer - segmented_0100_0\", width=1920, height=2160, left=2000)\n",
    "vis.add_geometry(pcd_display)\n",
    "vis.add_geometry(partial_pcd)\n",
    "#vis.add_geometry(coordinate_frame)\n",
    " \n",
    "transformation = np.eye(4)\n",
    " \n",
    "\n",
    "# folder = \"segmented_pointcloud_separated\"\n",
    "# folder = \"front_orientation3_separated\"\n",
    "folder = \"data/segmented\"\n",
    "\n",
    "def apply_transformation():\n",
    "    global transformation, pcd_display\n",
    "    tx = slider_tx.get()\n",
    "    ty = slider_ty.get()\n",
    "    tz = slider_tz.get()\n",
    "    rx = np.deg2rad(slider_rx.get())\n",
    "    ry = np.deg2rad(slider_ry.get())\n",
    "    rz = np.deg2rad(slider_rz.get())\n",
    "    R = o3d.geometry.get_rotation_matrix_from_xyz((rx, ry, rz))\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = [tx, ty, tz]\n",
    "    transformation = T\n",
    "    transformed_points = (R @ orig_points.T).T + np.array([tx, ty, tz])\n",
    "    pcd_display.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "    pcd_display.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    "    vis.update_geometry(pcd_display)\n",
    "    print(\"Applied transformation:\\n\", T)\n",
    " \n",
    " \n",
    "def move_to_centroid():\n",
    "    # Compute initial guess.\n",
    "    strawberry_centroid = np.mean(orig_points, axis=0)\n",
    "    partial_centroid = np.mean(partial_points, axis=0)\n",
    "    translation_init = partial_centroid - strawberry_centroid\n",
    "    init_tx, init_ty, init_tz = translation_init\n",
    "    init_rx, init_ry, init_rz = np.deg2rad(90), 0, 0\n",
    " \n",
    "    \n",
    " \n",
    "    # Define the objective function (Chamfer distance with a z-penalty).\n",
    "    def chamfer_distance(params):\n",
    "        tx, ty, tz, rx, ry, rz = params\n",
    "        R = o3d.geometry.get_rotation_matrix_from_xyz((rx, ry, rz))\n",
    "        transformed = (R @ orig_points.T).T + np.array([tx, ty, tz])\n",
    "        tree_partial = cKDTree(partial_points)\n",
    "        dists1, _ = tree_partial.query(transformed)\n",
    "        tree_trans = cKDTree(transformed)\n",
    "        dists2, _ = tree_trans.query(partial_points)\n",
    "        chamfer = np.mean(dists1**2) + np.mean(dists2**2)\n",
    "        penalty = 1000 * ((tz - init_tz)**2)  # Strongly penalize z shift\n",
    "        return chamfer + penalty\n",
    "    \n",
    "    # Run optimization starting from the initial guess.\n",
    "    x0 = [init_tx, init_ty, init_tz, init_rx, init_ry, init_rz]\n",
    "    res = minimize(chamfer_distance, x0, method='Nelder-Mead', options={'maxiter': 100})\n",
    "    optimal = res.x\n",
    "    print(\"Optimization result:\", optimal)\n",
    " \n",
    "    slider_tx.set(optimal[0])\n",
    "    slider_ty.set(optimal[1])\n",
    "    slider_tz.set(optimal[2])\n",
    "    slider_rx.set(np.rad2deg(optimal[3]))\n",
    "    slider_ry.set(np.rad2deg(optimal[4]))\n",
    "    slider_rz.set(np.rad2deg(optimal[5]))\n",
    " \n",
    "    apply_transformation()\n",
    "    print(\"Moved strawberry model to partial pointcloud's centroid.\")\n",
    " \n",
    "def save_transformation():\n",
    "    current_filename=os.path.basename(partial_files[partial_index-1])\n",
    "    identifier = current_filename.replace(\"segmented_\", \"\").replace(\".ply\", \"\")\n",
    "    \n",
    "    # os.makedirs(\"transformation_matrix_\", exist_ok=True)\n",
    "    # np.save(f\"transformation_matrix_/transformation_matrix_{identifier}.npy\", transformation)\n",
    "    # os.makedirs(\"transformation_orientation3_matrix\", exist_ok=True)\n",
    "    # np.save(f\"transformation_orientation3_matrix/transformation_matrix_{identifier}.npy\", transformation)\n",
    "    os.makedirs(\"transformation_detection_matrix\", exist_ok=True)\n",
    "    np.save(f\"transformation_detection_matrix/transformation_matrix_{identifier}.npy\", transformation)\n",
    "\n",
    "    transformed_points = (transformation[:3, :3] @ orig_points.T).T + transformation[:3, 3]\n",
    "    pcd_save = o3d.geometry.PointCloud()\n",
    "    pcd_save.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "    pcd_save.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    "    # os.makedirs(\"transformation_strawberry_model_\", exist_ok=True)\n",
    "    # o3d.io.write_point_cloud(f\"transformation_strawberry_model_/transformation_strawberry_model_{identifier}.ply\", pcd_save)\n",
    "    # os.makedirs(\"transformation_orientation3_model\", exist_ok=True)\n",
    "    # o3d.io.write_point_cloud(f\"transformation_orientation3_model/transformation_strawberry_model_{identifier}.ply\", pcd_save)\n",
    "    os.makedirs(\"transformation_detection_model\", exist_ok=True)\n",
    "    o3d.io.write_point_cloud(f\"transformation_detection_model/transformation_strawberry_model_{identifier}.ply\", pcd_save)\n",
    "\n",
    "    print(\"Saved transformation matrix and model for\", identifier)\n",
    "\n",
    "    \n",
    "def load_transformation():\n",
    "    current_filename = os.path.basename(partial_files[partial_index-1])\n",
    "    identifier = current_filename.replace(\"segmented_\", \"\").replace(\".ply\", \"\")\n",
    "    path = f\"transformation_detection_matrix/transformation_matrix_{identifier}.npy\"\n",
    "    if os.path.exists(path):\n",
    "        loaded_T = np.load(path)\n",
    "        # Update sliders with translation\n",
    "        slider_tx.set(loaded_T[0, 3])\n",
    "        slider_ty.set(loaded_T[1, 3])\n",
    "        slider_tz.set(loaded_T[2, 3])\n",
    "            # Compute Euler angles (assume rotation order x-y-z)\n",
    "        R = loaded_T[:3, :3]\n",
    "        sy = np.sqrt(R[0, 0]**2 + R[1, 0]**2)\n",
    "        if sy > 1e-6:\n",
    "            rx = np.arctan2(R[2, 1], R[2, 2])\n",
    "            ry = np.arctan2(-R[2, 0], sy)\n",
    "            rz = np.arctan2(R[1, 0], R[0, 0])\n",
    "        else:\n",
    "            rx = np.arctan2(-R[1, 2], R[1, 1])\n",
    "            ry = np.arctan2(-R[2, 0], sy)\n",
    "            rz = 0\n",
    "        slider_rx.set(np.rad2deg(rx))\n",
    "        slider_ry.set(np.rad2deg(ry))\n",
    "        slider_rz.set(np.rad2deg(rz))\n",
    "            # Apply the loaded transformation\n",
    "        global transformation\n",
    "        transformation = loaded_T\n",
    "        transformed_points = (loaded_T[:3, :3] @ orig_points.T).T + loaded_T[:3, 3]\n",
    "        pcd_display.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "        pcd_display.colors = o3d.utility.Vector3dVector(np.tile([1, 0, 0], (transformed_points.shape[0], 1)))\n",
    "        vis.update_geometry(pcd_display)\n",
    "        apply_transformation()\n",
    "\n",
    "        print(\"Loaded transformation from\", path)\n",
    "    else:\n",
    "        print(\"No saved transformation file for\", identifier)\n",
    "    \n",
    " \n",
    "# Process All function remains unchanged\n",
    "def process_all():\n",
    "\n",
    "    pattern = os.path.join(folder, \"segmented_*.ply\")\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    for filepath in files:\n",
    "        print(\"Processing\", filepath)\n",
    "        current_partial_pcd = o3d.io.read_point_cloud(filepath)\n",
    "        current_points = np.asarray(current_partial_pcd.points)\n",
    "        current_partial_pcd.colors = o3d.utility.Vector3dVector(np.tile([0, 0, 1], (current_points.shape[0], 1)))\n",
    "        global partial_points, partial_pcd\n",
    "        partial_points = current_points\n",
    "        try:\n",
    "            vis.remove_geometry(partial_pcd)\n",
    "        except:\n",
    "            pass\n",
    "        partial_pcd = current_partial_pcd\n",
    "        vis.add_geometry(partial_pcd)\n",
    "        strawberry_centroid = np.mean(orig_points, axis=0)\n",
    "        partial_centroid = np.mean(partial_points, axis=0)\n",
    "        translation = partial_centroid - strawberry_centroid\n",
    "        slider_tx.set(translation[0])\n",
    "        slider_ty.set(translation[1])\n",
    "        slider_tz.set(translation[2])\n",
    "        slider_rx.set(90)\n",
    "        slider_ry.set(0)\n",
    "        slider_rz.set(0)\n",
    "        apply_transformation()\n",
    "       \n",
    "        identifier = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        # identifier = os.path.basename(filename)\n",
    " \n",
    "        save_transformation(identifier)\n",
    "        vis.poll_events()\n",
    " \n",
    "# Create a sorted list of partial pointcloud files and an index for going to the next partial.\n",
    "# partial_files = sorted(glob.glob(os.path.join(folder, \"segmented_*.ply\")))\n",
    "partial_files = sorted(glob.glob(os.path.join(folder, \"filtered_points_*.ply\")))\n",
    "partial_index = 1   # Since the first file is already loaded\n",
    " \n",
    "def next_partial():\n",
    "    global partial_files, partial_index, partial_pcd, partial_points, vis\n",
    "    if partial_index >= len(partial_files):\n",
    "        print(\"No more partial pointclouds.\")\n",
    "        return\n",
    "    filename = partial_files[partial_index]\n",
    "    partial_index += 1\n",
    "    print(\"Loading\", filename)\n",
    "    # Read the new partial\n",
    "    new_partial = o3d.io.read_point_cloud(filename)\n",
    "    new_partial_points = np.asarray(new_partial.points)\n",
    "    new_partial.colors = o3d.utility.Vector3dVector(np.tile([0, 0, 1], (new_partial_points.shape[0], 1)))\n",
    "    partial_points = new_partial_points\n",
    "    try:\n",
    "        vis.remove_geometry(partial_pcd)\n",
    "    except:\n",
    "        pass\n",
    "    partial_pcd = new_partial\n",
    "    # Update sliders so that the strawberry model is centered on the partial\n",
    "    strawberry_centroid = np.mean(orig_points, axis=0)\n",
    "    partial_centroid = np.mean(partial_points, axis=0)\n",
    "    translation = partial_centroid - strawberry_centroid\n",
    "    slider_tx.set(translation[0])\n",
    "    slider_ty.set(translation[1])\n",
    "    slider_tz.set(translation[2])\n",
    "    slider_rx.set(90)\n",
    "    slider_ry.set(0)\n",
    "    slider_rz.set(0)\n",
    "    apply_transformation()\n",
    "    # Re-create the visualizer window with the new title (the title now shows the partial file name)\n",
    "    new_title = f\"Visualizer - {os.path.basename(filename)}\"\n",
    " \n",
    "    vis.destroy_window()\n",
    "    vis.create_window(new_title, width=1920, height=2160, left=2000)\n",
    "    vis.add_geometry(pcd_display)\n",
    "    vis.add_geometry(partial_pcd)\n",
    "    # vis.add_geometry(coordinate_frame)\n",
    "    print(\"Updated visualizer with new title.\")\n",
    " \n",
    "def update_visualizer():\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    root.after(50, update_visualizer)\n",
    " \n",
    "def create_slider_frame(parent, label_text, slider_from, slider_to, resolution):\n",
    "    frame = tk.Frame(parent)\n",
    "    frame.pack(pady=2)\n",
    "    tk.Label(frame, text=label_text).pack(side=tk.LEFT)\n",
    "    slider = tk.Scale(frame, from_=slider_from, to=slider_to, resolution=resolution,\n",
    "                      orient=tk.HORIZONTAL, length=200, command=lambda x: apply_transformation())\n",
    "    slider.pack(side=tk.LEFT)\n",
    "    btn_minus = tk.Button(frame, text=\"-\", command=lambda: slider.set(slider.get() - resolution))\n",
    "    btn_minus.pack(side=tk.LEFT, padx=2)\n",
    "    btn_plus = tk.Button(frame, text=\"+\", command=lambda: slider.set(slider.get() + resolution))\n",
    "    btn_plus.pack(side=tk.LEFT, padx=2)\n",
    "    return slider\n",
    " \n",
    "root = tk.Tk()\n",
    "root.title(\"Strawberry Transformation\")\n",
    " \n",
    "slider_tx = create_slider_frame(root, \"Translation X\", -1, 1, 0.001)\n",
    "slider_ty = create_slider_frame(root, \"Translation Y\", -1, 1, 0.001)\n",
    "slider_tz = create_slider_frame(root, \"Translation Z\", -1, 1, 0.001)\n",
    "slider_rx = create_slider_frame(root, \"Rotation X (deg)\", -180, 180, 0.5)\n",
    "slider_ry = create_slider_frame(root, \"Rotation Y (deg)\", -180, 180, 0.5)\n",
    "slider_rz = create_slider_frame(root, \"Rotation Z (deg)\", -180, 180, 0.5)\n",
    " \n",
    "btn_move = tk.Button(root, text=\"Move to Centroid\", command=move_to_centroid)\n",
    "btn_move.pack(pady=5)\n",
    " \n",
    "btn_load = tk.Button(root, text=\"Load Transformation\", command=load_transformation)\n",
    "btn_load.pack(pady=5) \n",
    " \n",
    " \n",
    "btn_save = tk.Button(root, text=\"Save Transformation\", command=lambda: save_transformation())\n",
    "btn_save.pack(pady=5)\n",
    "btn_process_all = tk.Button(root, text=\"Process All Partials\", command=process_all)\n",
    "btn_process_all.pack(pady=5)\n",
    " \n",
    "# New button to go to the next partial pointcloud\n",
    "btn_next = tk.Button(root, text=\"Next Partial\", command=next_partial)\n",
    "btn_next.pack(pady=5)\n",
    " \n",
    "root.after(50, update_visualizer)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert malak labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Define folders\n",
    "seg_folder = \"data/detection_data_539\"\n",
    "model_folder = \"data/transformation_detection_539_model\"\n",
    "matrix_folder = \"data/transformation_detection_539_matrix\"\n",
    "data_folder = \"data\"\n",
    "\n",
    "# Use this prefix to extract the identifier.\n",
    "prefix = \"transformation_strawberry_model_filtered_points_\"\n",
    "\n",
    "# Start index from 1000\n",
    "idx = 1133\n",
    "\n",
    "# Number of augmentations per original file (set to 1 here)\n",
    "num_augmentations = 2\n",
    "\n",
    "# Loop through all model files in model_folder\n",
    "for model_filename in os.listdir(model_folder):\n",
    "    if model_filename.endswith(\".ply\") and model_filename.startswith(prefix):\n",
    "        # Expected model file format:\n",
    "        # \"transformation_strawberry_model_filtered_points_<identifier>.ply\"\n",
    "        identifier = model_filename[len(prefix):].replace(\".ply\", \"\")\n",
    "        \n",
    "        # Construct file paths using the identifier\n",
    "        src_file = os.path.join(seg_folder, f\"filtered_points_{identifier}.ply\")\n",
    "        matrix_file = os.path.join(matrix_folder, f\"transformation_matrix_filtered_points_{identifier}.npy\")\n",
    "        model_file = os.path.join(model_folder, model_filename)\n",
    "        \n",
    "        # Read the source point cloud, the transformed model, and load the ground truth transformation matrix\n",
    "        src_pcd = o3d.io.read_point_cloud(src_file)\n",
    "        model_transformed_pcd = o3d.io.read_point_cloud(model_file)\n",
    "        transform_gt = np.load(matrix_file)\n",
    "        \n",
    "\n",
    "        # Get 512 points for original data\n",
    "        if len(src_pcd.points) >= 512:\n",
    "            downsampled_pcd = src_pcd.farthest_point_down_sample(512)\n",
    "            src_points = np.asarray(downsampled_pcd.points)\n",
    "        else:\n",
    "            original_points = np.asarray(src_pcd.points)\n",
    "            repeats_needed = int(np.ceil(512 / len(original_points)))\n",
    "            src_points = np.tile(original_points, (repeats_needed, 1))[:512]\n",
    "\n",
    "        # # Convert point clouds to numpy arrays\n",
    "        # src_points = np.asarray(src_pcd.points)\n",
    "        model_transformed_points = np.asarray(model_transformed_pcd.points)\n",
    "        \n",
    "        # Save the original data in the specified format\n",
    "        output_path = os.path.join(data_folder, f\"processed_dataset_{idx}.npz\")\n",
    "        np.savez(output_path,\n",
    "                 src_pcd=src_points,\n",
    "                 transform_gt=transform_gt,\n",
    "                 model_pcd_transformed=model_transformed_points)\n",
    "        print(f\"Saved evaluation data to {output_path}\")\n",
    "        idx += 1\n",
    "        \n",
    "        # Create and save augmented version(s)\n",
    "        for aug in range(num_augmentations):\n",
    "            translation = np.random.uniform(-1, 1, 3)\n",
    "            src_aug = src_points + translation\n",
    "            model_transformed_aug = model_transformed_points + translation\n",
    "            \n",
    "            aug_output_path = os.path.join(data_folder, f\"processed_dataset_{idx}.npz\")\n",
    "            np.savez(aug_output_path,\n",
    "                     src_pcd=src_aug,\n",
    "                     transform_gt=transform_gt,\n",
    "                     model_pcd_transformed=model_transformed_aug)\n",
    "            print(f\"Saved augmented evaluation data to {aug_output_path}\")\n",
    "            idx += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vis lablels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import open3d as o3d\n",
    "folder = \"data/segmented\"\n",
    "out_folder = \"transformation_detection_model\"\n",
    "frame = \"0100\"\n",
    "detection_num = \"1\"\n",
    "in_file = os.path.join(folder, f\"filtered_points_{frame}_detection_{detection_num}.ply\")\n",
    "out_file = os.path.join(out_folder, f\"transformation_strawberry_model_filtered_points_{frame}_detection_{detection_num}.ply\")\n",
    "\n",
    "pcd_input = o3d.io.read_point_cloud(in_file)\n",
    "pcd_model = o3d.io.read_point_cloud(out_file)\n",
    "\n",
    "\n",
    "pcd_input.paint_uniform_color([0, 1, 0])   # Green for the input point cloud\n",
    "pcd_model.paint_uniform_color([0, 0, 1])   # Blue for the transformed model\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_input, pcd_model])\n",
    "\n",
    "\n",
    "# partial_files = sorted(glob.glob(os.path.join(folder, \"filtered_points_*.ply\")))\n",
    "# partial_index = 1   # Since the first file is already loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert labels to stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Define folders\n",
    "seg_folder = \"data/segmented\"\n",
    "model_folder = \"transformation_detection_model\"\n",
    "matrix_folder = \"transformation_detection_matrix\"\n",
    "data_folder = \"data\"\n",
    "\n",
    "# Use this prefix to extract the identifier.\n",
    "prefix = \"transformation_strawberry_model_filtered_points_\"\n",
    "\n",
    "# Start index from 1000\n",
    "idx = 1000\n",
    "\n",
    "# Number of augmentations per original file (set to 1 here)\n",
    "num_augmentations = 2\n",
    "\n",
    "# Loop through all model files in model_folder\n",
    "for model_filename in os.listdir(model_folder):\n",
    "    if model_filename.endswith(\".ply\") and model_filename.startswith(prefix):\n",
    "        # Expected model file format:\n",
    "        # \"transformation_strawberry_model_filtered_points_<identifier>.ply\"\n",
    "        identifier = model_filename[len(prefix):].replace(\".ply\", \"\")\n",
    "        \n",
    "        # Construct file paths using the identifier\n",
    "        src_file = os.path.join(seg_folder, f\"filtered_points_{identifier}.ply\")\n",
    "        matrix_file = os.path.join(matrix_folder, f\"transformation_matrix_filtered_points_{identifier}.npy\")\n",
    "        model_file = os.path.join(model_folder, model_filename)\n",
    "        \n",
    "        # Read the source point cloud, the transformed model, and load the ground truth transformation matrix\n",
    "        src_pcd = o3d.io.read_point_cloud(src_file)\n",
    "         # Process original points\n",
    "        \n",
    "\n",
    "        # Get 512 points for original data\n",
    "        if len(src_pcd.points) >= 512:\n",
    "            downsampled_pcd = src_pcd.farthest_point_down_sample(512)\n",
    "            src_points = np.asarray(downsampled_pcd.points)\n",
    "        else:\n",
    "            original_points = np.asarray(src_pcd.points)\n",
    "            repeats_needed = int(np.ceil(512 / len(original_points)))\n",
    "            src_points = np.tile(original_points, (repeats_needed, 1))[:512]\n",
    "\n",
    "        model_transformed_pcd = o3d.io.read_point_cloud(model_file)\n",
    "        transform_gt = np.load(matrix_file)\n",
    "        \n",
    "        # Convert point clouds to numpy arrays\n",
    "        # src_points = np.asarray(src_pcd.points)\n",
    "\n",
    "        model_transformed_points = np.asarray(model_transformed_pcd.points)\n",
    "        \n",
    "        # Save the original data in the specified format\n",
    "        output_path = os.path.join(data_folder, f\"processed_dataset_{idx}.npz\")\n",
    "        np.savez(output_path,\n",
    "                 src_pcd=src_points,\n",
    "                 transform_gt=transform_gt,\n",
    "                 model_pcd_transformed=model_transformed_points)\n",
    "        print(f\"Saved evaluation data to {output_path}\")\n",
    "        idx += 1\n",
    "        \n",
    "        # Create and save augmented version(s)\n",
    "        for aug in range(num_augmentations):\n",
    "            translation = np.random.uniform(-1, 1, 3)\n",
    "            src_aug = src_points + translation\n",
    "            model_transformed_aug = model_transformed_points + translation\n",
    "            \n",
    "            aug_output_path = os.path.join(data_folder, f\"processed_dataset_{idx}.npz\")\n",
    "            np.savez(aug_output_path,\n",
    "                     src_pcd=src_aug,\n",
    "                     transform_gt=transform_gt,\n",
    "                     model_pcd_transformed=model_transformed_aug)\n",
    "            print(f\"Saved augmented evaluation data to {aug_output_path}\")\n",
    "            idx += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize converted stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file = os.path.join(data_folder, \"processed_dataset_1032.npz\")\n",
    "data_eval = np.load(eval_file)\n",
    "\n",
    "src_points = data_eval['src_pcd']\n",
    "model_points = data_eval['model_pcd_transformed']\n",
    "\n",
    "pcd_src = o3d.geometry.PointCloud()\n",
    "pcd_src.points = o3d.utility.Vector3dVector(src_points)\n",
    "pcd_src.paint_uniform_color([0, 1, 0])  # green for source\n",
    "\n",
    "pcd_model = o3d.geometry.PointCloud()\n",
    "pcd_model.points = o3d.utility.Vector3dVector(model_points)\n",
    "pcd_model.paint_uniform_color([0, 0, 1])  # blue for transformed model\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_src, pcd_model])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
